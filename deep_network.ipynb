{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar  9 22:36:45 2020\n",
    "\n",
    "@author: qingn\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Mar  1 11:40:47 2020\n",
    "5043_hw4\n",
    "@author: qingn\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from itertools import product\n",
    "import hw2_base\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "import random\n",
    "import re\n",
    "\n",
    "# From pypng\n",
    "import png\n",
    "#from sklearn.p\n",
    "import sklearn.metrics\n",
    "\n",
    "##################\n",
    "# Configure figure parameters\n",
    "\n",
    "FONTSIZE = 18\n",
    "FIGURE_SIZE = (10,4)\n",
    "FIGURE_SIZE2 = (10,10)\n",
    "\n",
    "plt.rcParams.update({'font.size': FONTSIZE})\n",
    "plt.rcParams['figure.figsize'] = FIGURE_SIZE\n",
    "# Default tick label size\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "\n",
    "# Image Reading\n",
    "def readPngFile(filename):\n",
    "    '''\n",
    "    Read a single PNG file\n",
    "    \n",
    "    filename = fully qualified file name\n",
    "    \n",
    "    Return: 3D numpy array (rows x cols x chans)\n",
    "    \n",
    "    Note: all pixel values are floats in the range 0.0 .. 1.0\n",
    "    \n",
    "    This implementation relies on the pypng package\n",
    "    '''\n",
    "    #print(\"reading:\", filename)\n",
    "    # Load in the image meta-data\n",
    "    r = png.Reader(filename)\n",
    "    it = r.read()\n",
    "    \n",
    "    # Load in the image itself and convert to a 2D array\n",
    "    image_2d = np.vstack(map(np.uint8, it[2]))\n",
    "    \n",
    "    # Reshape into rows x cols x chans\n",
    "    image_3d = np.reshape(image_2d,\n",
    "                         (it[0],it[1],it[3]['planes'])) / 255.0\n",
    "    return image_3d\n",
    "\n",
    "def read_images_from_directory(directory, file_regexp):\n",
    "    '''\n",
    "    Read a set of images from a directory.  All of the images must be the same size\n",
    "    \n",
    "    directory = Directory to search\n",
    "    \n",
    "    file_regexp = a regular expression to match the file names against\n",
    "    \n",
    "    Return: 4D numpy array (images x rows x cols x chans)\n",
    "    '''\n",
    "    \n",
    "    print(directory, file_regexp)\n",
    "    # Get all of the file names\n",
    "    files = sorted(os.listdir(directory))\n",
    "    \n",
    "    # Construct a list of images from those that match the regexp\n",
    "    list_of_images = [readPngFile(directory + \"/\" + f) for f in files if re.search(file_regexp, f) ]\n",
    "    \n",
    "    # Create a 3D numpy array\n",
    "    return np.array(list_of_images, dtype=np.float32)\n",
    "\n",
    "def read_image_set_from_directories(directory, spec):\n",
    "    '''\n",
    "    Read a set of images from a set of directories\n",
    "    \n",
    "    directory  = base directory to read from\n",
    "    \n",
    "    spec = n x 2 array of subdirs and file regexps\n",
    "    \n",
    "    Return: 4D numpy array (images x rows x cols x chans)\n",
    "    \n",
    "    '''\n",
    "    out = read_images_from_directory(directory + \"/\" + spec[0][0], spec[0][1])\n",
    "    for sp in spec[1:]:\n",
    "        out = np.append(out, read_images_from_directory(directory + \"/\" + sp[0], sp[1]), axis=0)\n",
    "    return out\n",
    "\n",
    "def load_multiple_image_sets_from_directories(directory_base, directory_list, object_list, test_files):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    print(\"##################\")\n",
    "    # Create the list of object/image specs\n",
    "    inputs = [[obj, test_files] for obj in object_list]\n",
    "    \n",
    "    # First directory\n",
    "    ret = read_image_set_from_directories(directory_base + \"/\" + directory_list[0], inputs)\n",
    "    \n",
    "    # Loop over directories\n",
    "    for directory in directory_list[1:]:\n",
    "        ret = np.append(ret,\n",
    "                        read_image_set_from_directories(directory_base + \"/\" + directory, inputs),\n",
    "                        axis=0)\n",
    "\n",
    "    return ret\n",
    "### Create Network\n",
    "def create_classifier_network(image_size, nchannels, n_classes=2, lambda_l2=.0001, p_dropout=0.5):\n",
    "    '''\n",
    "    This is to create a deep network with the argParser\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(image_size[0],image_size[1], nchannels),name ='input'))\n",
    "    \n",
    "   \n",
    "    ### Fill in detail\n",
    "    for j in range(4):\n",
    "        model.add(Convolution2D(filters = args.conv_nfilters[j], \n",
    "                            kernel_size = (args.conv_size[j],args.conv_size[j]), \n",
    "                            strides =(1,1), \n",
    "                            padding='valid', \n",
    "                            use_bias = True, \n",
    "                            kernel_initializer='random_uniform',\n",
    "                            bias_initializer = 'zeros',\n",
    "                            name = 'C%s'%(j), \n",
    "                            activation = 'elu',\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))# valid is cutting down the size\n",
    "        model.add(MaxPooling2D(pool_size= (2,2),\n",
    "                           strides=(2,2),\n",
    "                           padding = 'valid'                     \n",
    "                           ))\n",
    "    model.add(Flatten())\n",
    "    for i in range(3):\n",
    "        model.add(Dense(units = args.hidden[i],activation='elu',use_bias=True,kernel_initializer='truncated_normal',\n",
    "                   bias_initializer='zeros',name='D_%s'%(i),kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))\n",
    "        if p_dropout is not None:\n",
    "            model.add(Dropout(p_dropout))\n",
    "#    model.add(Dropout(p_dropout))\n",
    "        i = i+1\n",
    "        \n",
    "    model.add(Dense(units=n_classes,\n",
    "                   activation='softmax',\n",
    "                    use_bias=True,\n",
    "                    bias_initializer='zeros',\n",
    "                    kernel_initializer='truncated_normal',name = 'output',\n",
    "                   kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)\n",
    "             ))\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                                epsilon=None, decay=0.0, amsgrad=False)\n",
    "#     keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer =opt, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def shallow_create_classifier_network(image_size, nchannels, n_classes=2, lambda_l2=.0001, p_dropout=0.5):\n",
    "    '''\n",
    "    This is to create a shallow network with the argParser\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(image_size[0],image_size[1], nchannels),name ='input'))\n",
    "    \n",
    "   \n",
    "    ### Fill in detail\n",
    "    for j in range(2):\n",
    "        model.add(Convolution2D(filters = args.conv_nfilters[j], \n",
    "                            kernel_size = (args.conv_size[j],args.conv_size[j]), \n",
    "                            strides =(1,1), \n",
    "                            padding='valid', \n",
    "                            use_bias = True, \n",
    "                            kernel_initializer='random_uniform',\n",
    "                            bias_initializer = 'zeros',\n",
    "                            name = 'C%s'%(j), \n",
    "                            activation = 'elu',\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))# valid is cutting down the size\n",
    "        model.add(MaxPooling2D(pool_size= (2,2),\n",
    "                           strides=(2,2),\n",
    "                           padding = 'valid'                     \n",
    "                           ))\n",
    "    model.add(Flatten())\n",
    "    for i in range(1):\n",
    "        model.add(Dense(units = args.hidden[i],activation='elu',use_bias=True,kernel_initializer='truncated_normal',\n",
    "                   bias_initializer='zeros',name='D_%s'%(i),kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))\n",
    "        if p_dropout is not None:\n",
    "            model.add(Dropout(p_dropout))\n",
    "#    model.add(Dropout(p_dropout))\n",
    "        i = i+1\n",
    "        \n",
    "    model.add(Dense(units=n_classes,\n",
    "                   activation='softmax',\n",
    "                    use_bias=True,\n",
    "                    bias_initializer='zeros',\n",
    "                    kernel_initializer='truncated_normal',name = 'output',\n",
    "                   kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)\n",
    "             ))\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                                epsilon=None, decay=0.0, amsgrad=False)\n",
    "#     keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer =opt, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def training_set_generator_images(ins, outs, batch_size=10,\n",
    "                          input_name='input', \n",
    "                        output_name='output'):\n",
    "    '''\n",
    "    Generator for producing random mini-batches of image training samples.\n",
    "    \n",
    "    @param ins Full set of training set inputs (examples x row x col x chan)\n",
    "    @param outs Corresponding set of sample (examples x nclasses)\n",
    "    @param batch_size Number of samples for each minibatch\n",
    "    @param input_name Name of the model layer that is used for the input of the model\n",
    "    @param output_name Name of the model layer that is used for the output of the model\n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        # Randomly select a set of example indices\n",
    "        example_indices = random.choices(range(ins.shape[0]), k=batch_size)\n",
    "        \n",
    "        # The generator will produce a pair of return values: one for inputs and one for outputs\n",
    "        yield({input_name: ins[example_indices,:,:,:]},{output_name: outs[example_indices,:]})\n",
    "### Evaluation\n",
    "def generate_roc(model, ins, outs, ins_validation, outs_validation):\n",
    "    '''\n",
    "    Produce a ROC plot given a model, a set of inputs and the true outputs\n",
    "    \n",
    "    Assume that model produces N-class output; we will only look at the class 0 scores\n",
    "    '''\n",
    "    # Compute probabilistic predictions given images\n",
    "    pred = model.predict(ins)\n",
    "    # Compute false positive rate & true positive rate + AUC\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(outs[:,0], pred[:,0])\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Compute probabilistic predictions given images\n",
    "    pred_val = model.predict(ins_validation)\n",
    "    # Compute false positive rate & true positive rate + AUC\n",
    "    fpr_val, tpr_val, thresholds_val = sklearn.metrics.roc_curve(outs_validation[:,0], pred_val[:,0])\n",
    "    auc_val = sklearn.metrics.auc(fpr_val, tpr_val)\n",
    "    \n",
    "    \n",
    "    # Generate the plot\n",
    "    fig1 = plt.figure(1)\n",
    "    plt.axis('equal')\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.plot(fpr, tpr, 'b', label='Train AUC = {:.3f}'.format(auc))\n",
    "    plt.plot(fpr_val, tpr_val, 'r', label='Validation AUC = {:.3f}'.format(auc_val))\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('FPR', fontsize=FONTSIZE)\n",
    "    plt.ylabel('TPR', fontsize=FONTSIZE)\n",
    "    fig1.tight_layout()\n",
    "    plt.savefig(os.getcwd()+'ROC1'+'.png')\n",
    "            \n",
    "# generate_roc(model, ins, outs, ins_validation, outs_validation)  \n",
    "\n",
    "### Visualize Model Internals      \n",
    "def intermediate_model_state(model, ins, layer_list):\n",
    "    '''\n",
    "    Return layer activations for intermediate layers in a model for a set of examples\n",
    "    \n",
    "    :param model: Model in question\n",
    "    :param ins: Input tensor (examples, rows, cols, channels)\n",
    "    :param layer_list: List of layer names to produce activations for\n",
    "    :returns: a list of numpy arrays\n",
    "    '''\n",
    "    # Translate layer names into corresponding output tensors\n",
    "    layer_outputs = [l.output for l in model.layers if l.name in layer_list]\n",
    "    \n",
    "    # Construct a new Keras model that outputs these tensors\n",
    "    # The internal structure of the model itself is referenced through the input and output tensor lists\n",
    "    new_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Evaluate the new model\n",
    "    activations = new_model.predict(ins_validation)\n",
    "    \n",
    "    # Return a list of activation numpy arrays\n",
    "    return activations\n",
    "\n",
    "def visualize_state(activations, width=1, example=0, cmap='plasma'):\n",
    "    '''\n",
    "    Produce graphical representation of a set of image channels\n",
    "    \n",
    "    :param activations: numpy array (example, rows, cols, channels)\n",
    "    :param width: Number of images displayed horizontally\n",
    "    :param example: Index of example to display\n",
    "    :param cmap: Color map to use for plotting\n",
    "    '''\n",
    "    # Size of the individual images\n",
    "    nrows = activations.shape[1]\n",
    "    ncols = activations.shape[2]\n",
    "    # Number of channels\n",
    "    nfilters = activations.shape[3]\n",
    "    \n",
    "    # Tile all of the sub-images \n",
    "    grid = np.zeros((int((nfilters-1)/width + 1) * nrows, ncols * width))\n",
    "    \n",
    "    # Loop over image\n",
    "    for i in range(nfilters):\n",
    "        # Compute r,c of tile to place the ith image into\n",
    "        r = int(i / width)\n",
    "        c = i % width\n",
    "        grid[nrows*r: nrows*(r+1), ncols*c:ncols*(c+1)] = activations[example,:,:,i]\n",
    "        \n",
    "    # Plot\n",
    "    plt.matshow(grid, cmap=cmap) \n",
    "    \n",
    "# Compute activations for 2 layers over a set of examples\n",
    "#layer_list=['C1']\n",
    "#activations = intermediate_model_state(model, ins_validation, layer_list)\n",
    "## Plot convolutional layers 1 and 2\n",
    "#example=29\n",
    "#plt.imshow(ins_validation[example,:,:,:])\n",
    "#visualize_state(activations, width=10, example=example)\n",
    "##visualize_state(activations[0], width=10, example=example)\n",
    "##visualize_state(activations[1], width=20, example=example)\n",
    "##visualize_state(activations[2], width=20, example=example)\n",
    "##visualize_state(activations[3], width=30, example=example)\n",
    "\n",
    "#%%\n",
    "'''Load data sets'''\n",
    "    \n",
    "## File location\n",
    "# directory_base = '/home/fagg/datasets/core50/core50_128x128'\n",
    "directory_base = '/Users/qingn/Downloads/core50_128x128'\n",
    "\n",
    "# Training set: define which files to load for each object\n",
    "#test_files = '.*[05].png'\n",
    "test_files = '.*0.png'\n",
    "\n",
    "### Positive cases\n",
    "# Define which objects to load\n",
    "#object_list = ['o25', 'o22', 'o23', 'o24']\n",
    "object_list = ['o15', 'o12', 'o13', 'o14']\n",
    "#object_list = ['o13']\n",
    "\n",
    "# Define which conditions to load\n",
    "condition_list = ['s1', 's2', 's3', 's4', 's5', 's7', 's8', 's9', 's10', 's11']\n",
    "#condition_list = ['s1', 's2', 's3', 's4']\n",
    "#condition_list = ['s1', 's2','s3', 's4']\n",
    "\n",
    "# Load all of the objects/condition\n",
    "ins_pos = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list, test_files)\n",
    "\n",
    "### Negative cases\n",
    "# Define which objects to load\n",
    "object_list2 = ['o45', 'o42', 'o43', 'o44']\n",
    "#object_list2 = ['o42']\n",
    "ins_neg = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list2, test_files)\n",
    "\n",
    "### Combine positives and negatives into a common data set\n",
    "outs_pos = np.append(np.ones((ins_pos.shape[0],1)), np.zeros((ins_pos.shape[0],1)), axis=1)\n",
    "outs_neg = np.append(np.zeros((ins_neg.shape[0],1)), np.ones((ins_neg.shape[0],1)), axis=1)\n",
    "\n",
    "ins = np.append(ins_pos, ins_neg, axis=0)\n",
    "outs = np.append(outs_pos, outs_neg, axis=0)\n",
    "#%%\n",
    "########################################################################\n",
    "# Validation set\n",
    "# Define which files to load for each object\n",
    "test_files = '.*0.png'\n",
    "\n",
    "### Positives\n",
    "# Define which objects to |load\n",
    "object_list = ['o11']\n",
    "#object_list = ['o21']\n",
    "\n",
    "# Load the positives\n",
    "ins_pos_validation = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list, test_files)\n",
    "\n",
    "### Negatives\n",
    "# Define objects\n",
    "object_list2 = ['o41']\n",
    "#object_list2 = ['o41']\n",
    "\n",
    "# Load the negative cases\n",
    "ins_neg_validation = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list2, test_files)\n",
    "\n",
    "### Combine positives and negatives\n",
    "outs_pos_validation = np.append(np.ones((ins_pos_validation.shape[0], 1)), np.zeros((ins_pos_validation.shape[0], 1)), axis=1)\n",
    "outs_neg_validation = np.append(np.zeros((ins_neg_validation.shape[0], 1)), np.ones((ins_neg_validation.shape[0], 1)), axis=1)\n",
    "\n",
    "ins_validation = np.append(ins_pos_validation, ins_neg_validation, axis=0)\n",
    "outs_validation = np.append(outs_pos_validation, outs_neg_validation, axis=0)\n",
    "#%%\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q_parser = hw2_base.create_parser()\n",
    "\n",
    "    args = q_parser.parse_args()\n",
    "    hw2_base.check_args(args)\n",
    "#     execute_exp_1(args)\n",
    "# def execute_exp_1(args=None):\n",
    "#     '''\n",
    "#     Perform the training and evaluation for a single model\n",
    "    \n",
    "#     @args Argparse arguments\n",
    "#     '''\n",
    "#     hw2_base.augment_args(args)\n",
    "    generator = training_set_generator_images(ins, outs, batch_size=args.batch)#\n",
    "    # Build the model\n",
    "    model = create_classifier_network((ins.shape[1], ins.shape[2]), ins.shape[3], 2)\n",
    "    # Callbacks\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=args.patience,\n",
    "                                                      restore_best_weights=True,\n",
    "                                                         min_delta=0.01)\n",
    "\n",
    "    # Learn\n",
    "    history = model.fit_generator(generator,\n",
    "                                  epochs=int(args.epochs*5),\n",
    "                                  steps_per_epoch=2,\n",
    "                                  use_multiprocessing=True, \n",
    "                                  verbose=args.verbose>=2,\n",
    "                                  validation_data=(ins_validation, outs_validation),\n",
    "                                  callbacks=[early_stopping_cb])\n",
    "    #    history_all.append(history)\n",
    "    generate_roc(model, ins, outs, ins_validation, outs_validation)\n",
    "\n",
    "    # # Generate log data\n",
    "    # results = {}\n",
    "    # results['history'] = history.history\n",
    "    # print(history.history['val_accuracy'])\n",
    "    # # Save results\n",
    "    # fbase =hw2_base.generate_fname(args)\n",
    "    # results['fname_base'] = fbase\n",
    "    # fp = open(\"%s_results.pkl\"%(fbase), \"wb\")\n",
    "    # pickle.dump(results, fp)\n",
    "    # fp.close()\n",
    "    # # Model\n",
    "    # model.save(\"%s_model\"%(fbase))\n",
    "    # return model\n",
    "    #%\n",
    "    #run network.py -vv -epochs 2000 -patience 400 -conv_size 3 5 5 5 -conv_nfilters 10 15 20 25 -hidden 200 50 10 -L2_regularizer .003 -lrate 0.0002 -batch 200\n",
    "    fig = plt.figure()\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.show()\n",
    "    print(history.history['val_accuracy'])\n",
    "    plt.title('val_accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "#     fig.tight_layout()\n",
    "#     plt.savefig(os.getcwd()+'hw4_deep'+'.png') \n",
    "\n",
    "    #%%\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
